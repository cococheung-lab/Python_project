{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cad15b3-fe87-4065-8dec-ceccf4e78e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting helium\n",
      "  Downloading helium-5.0.0.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: selenium>=4.16.0 in d:\\web_scraping\\venv\\lib\\site-packages (from helium) (4.16.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in d:\\web_scraping\\venv\\lib\\site-packages (from selenium>=4.16.0->helium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\web_scraping\\venv\\lib\\site-packages (from selenium>=4.16.0->helium) (0.23.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\web_scraping\\venv\\lib\\site-packages (from selenium>=4.16.0->helium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\web_scraping\\venv\\lib\\site-packages (from selenium>=4.16.0->helium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in d:\\web_scraping\\venv\\lib\\site-packages (from trio~=0.17->selenium>=4.16.0->helium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\web_scraping\\venv\\lib\\site-packages (from trio~=0.17->selenium>=4.16.0->helium) (2.4.0)\n",
      "Requirement already satisfied: idna in d:\\web_scraping\\venv\\lib\\site-packages (from trio~=0.17->selenium>=4.16.0->helium) (3.6)\n",
      "Requirement already satisfied: outcome in d:\\web_scraping\\venv\\lib\\site-packages (from trio~=0.17->selenium>=4.16.0->helium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\web_scraping\\venv\\lib\\site-packages (from trio~=0.17->selenium>=4.16.0->helium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\web_scraping\\venv\\lib\\site-packages (from trio~=0.17->selenium>=4.16.0->helium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\web_scraping\\venv\\lib\\site-packages (from trio-websocket~=0.9->selenium>=4.16.0->helium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in d:\\web_scraping\\venv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.16.0->helium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\web_scraping\\venv\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium>=4.16.0->helium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\web_scraping\\venv\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.16.0->helium) (0.14.0)\n",
      "Building wheels for collected packages: helium\n",
      "  Building wheel for helium (pyproject.toml): started\n",
      "  Building wheel for helium (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for helium: filename=helium-5.0.0-py3-none-any.whl size=30270 sha256=793dcb0111aa97c17f5b16ad1c11460aca1c8c08905f7264f2659f63451afc7d\n",
      "  Stored in directory: c:\\users\\coco\\appdata\\local\\pip\\cache\\wheels\\a8\\15\\3a\\f3f12ee458ca6458d50dd6af6c0348710c291f4fe567b99ee0\n",
      "Successfully built helium\n",
      "Installing collected packages: helium\n",
      "Successfully installed helium-5.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install helium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7b888be-6ecd-48f9-9e4c-acd2b859b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top products of the week:\n",
      "Product: Woolworths Santa Jar With Party Mix 300g, Rating: 4.5\n",
      "Product: Baxter's Straps Beef 250g, Rating: 4.5\n",
      "Product: Woolworths Christmas Marshmallows 300g, Rating: 4.5\n",
      "Latest Product Reviews:\n",
      "Product: Woolworths Mini Choc Chip Muffin 8 Pack, Rating: 4, Comment: Great tasting, Date: January 12, 2024 1:07 AM\n",
      "Product: Woolworths Aussie Beef Gluten Free Sausage M ..., Rating: 5, Comment: Home made sausage rolls, Date: January 12, 2024 1:07 AM\n",
      "Product: Free From Gluten and Dairy Garlic Bread 250g, Rating: 5, Comment: Great quality, Date: January 12, 2024 1:03 AM\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://bunch.woolworths.com.au/s/home')\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "soup1 = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "product_elements = soup2.find_all('a', {'class': 'product-tile__title prod-name'})\n",
    "rating_elements = soup2.find_all('div', {'class': 'rating rating--product-tile-slip', 'data-rating': True})\n",
    "\n",
    "print('Top products of the week:')\n",
    "for product_element, rating_element in zip(product_elements, rating_elements):\n",
    "    product = product_element.get_text(strip=True)\n",
    "    rating = rating_element['data-rating']\n",
    "    print(f\"Product: {product}, Rating: {rating}\")\n",
    "\n",
    "link_element = WebDriverWait(browser,5).until(EC.element_to_be_clickable((By.XPATH, '//a[contains(@href, \"/products\") and contains(text(), \"See more products\")]')))\n",
    "link_element.click()\n",
    "\n",
    "Review_product_elements = soup2.find_all('a', {'class': 'comment__link prod-name'})\n",
    "Review_rating_elements = soup2.find_all('div', {'class': 'rating rating--comment', 'data-rating': True})\n",
    "Review_comment_elements = soup2.find_all('h4', {'class': 'comment__title'})\n",
    "Review_date_elements = soup2.find_all('div', {'class': 'comment__date'})\n",
    "\n",
    "if not Review_product_elements or Review_rating_elements or Review_comment_elements or Review_date_elements:\n",
    "    current_url = browser.current_url\n",
    "    browser.get(current_url)\n",
    "    time.sleep(5)\n",
    "    soup1 = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "    Review_product_elements = soup2.find_all('a', {'class': 'comment__link prod-name'})\n",
    "    Review_rating_elements = soup2.find_all('div', {'class': 'rating rating--comment', 'data-rating': True})\n",
    "    Review_comment_elements = soup2.find_all('h4', {'class': 'comment__title'})\n",
    "    Review_date_elements = soup2.find_all('div', {'class': 'comment__date'})\n",
    "\n",
    "print('Latest Product Reviews:')\n",
    "for Review_product_element, Review_rating_element, Review_comment_element, Review_date_element in zip(Review_product_elements, Review_rating_elements,Review_comment_elements,Review_date_elements):\n",
    "    Review_product = Review_product_element.get_text(strip=True)\n",
    "    Review_rating = Review_rating_element['data-rating']\n",
    "    Review_comment = Review_comment_element.get_text(strip=True)\n",
    "    Review_date = Review_date_element.get_text(strip=True)\n",
    "    print(f\"Product: {Review_product}, Rating: {Review_rating}, Comment: {Review_comment}, Date: {Review_date}\")\n",
    "\n",
    "# browser.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c83f6-01f6-4ad4-85d2-8364785368c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c1771-76db-4bba-80f2-f121c050d0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93890a3b-916a-4e77-8d58-1b0cfaaa6ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
